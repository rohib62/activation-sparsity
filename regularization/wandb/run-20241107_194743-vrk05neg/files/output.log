Loading model with tensor parallelism...
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.35it/s]
Loading tokenizer...
Initializing trainer...
Loading dataset...
Setting up optimizer and scheduler...
Starting training...
Epoch 1:   0%|                                                                        | 14/13001 [00:05<1:18:49,  2.75it/s, task_loss=nan, reg_loss=nan]
Traceback (most recent call last):
  File "/home/riyasatohib_cohere_com/repos/teal_clone/regularization/act_reg.py", line 356, in <module>
    main()
  File "/home/riyasatohib_cohere_com/repos/teal_clone/regularization/act_reg.py", line 340, in main
    model = train(
            ^^^^^^
  File "/home/riyasatohib_cohere_com/repos/teal_clone/regularization/act_reg.py", line 240, in train
    total_loss.backward()
  File "/home/riyasatohib_cohere_com/.conda/envs/teal/lib/python3.11/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/riyasatohib_cohere_com/.conda/envs/teal/lib/python3.11/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/home/riyasatohib_cohere_com/.conda/envs/teal/lib/python3.11/site-packages/torch/autograd/graph.py", line 768, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
