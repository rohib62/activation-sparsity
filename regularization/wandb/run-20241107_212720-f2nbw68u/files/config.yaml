_wandb:
    value:
        cli_version: 0.18.6
        m: []
        python_version: 3.11.10
        t:
            "1":
                - 1
                - 11
                - 49
                - 51
                - 55
                - 71
            "2":
                - 1
                - 11
                - 49
                - 51
                - 55
                - 71
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.11.10
            "5": 0.18.6
            "6": 4.44.1
            "8":
                - 5
            "12": 0.18.6
            "13": linux-x86_64
batch_size:
    value: 8
disable_wandb:
    value: false
gradient_accumulation_steps:
    value: 4
learning_rate:
    value: 2e-05
log_every:
    value: 10
max_grad_norm:
    value: 1
max_length:
    value: 512
model_path:
    value: /home/riyasatohib_cohere_com/repos/models/meta-llama/Meta-Llama-3-8B
num_epochs:
    value: 3
output_dir:
    value: ./output
wandb_project:
    value: llama-finetuning
warmup_ratio:
    value: 0.03
